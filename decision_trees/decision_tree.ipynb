{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed:    2.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Load Data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m X, y = \u001b[43mload_data_hog_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) == \u001b[32m0\u001b[39m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCRITICAL ERROR: No data loaded.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mload_data_hog_parallel\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     47\u001b[39m df.rename(columns=\u001b[38;5;28;01mlambda\u001b[39;00m x: x.lower().strip(), inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     48\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.lower().str.strip()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_single_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m results = [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m     57\u001b[39m X = np.array([r[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "img_size = (48, 48)\n",
    "\n",
    "try:\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    script_dir = os.getcwd()\n",
    "\n",
    "project_root = os.path.dirname(script_dir)\n",
    "legend_path = os.path.join(project_root, \"facial_expressions\", \"data\", \"legend.csv\")\n",
    "image_dir = os.path.join(project_root, \"facial_expressions\", \"images\")\n",
    "\n",
    "# Clean Data\n",
    "def load_data_hog():\n",
    "    if not os.path.exists(legend_path):\n",
    "        print(f\"Error: CSV not found at {legend_path}\")\n",
    "        return None, None\n",
    "\n",
    "    df = pd.read_csv(legend_path)\n",
    "    df.rename(columns=lambda x: x.lower().strip(), inplace=True)\n",
    "    df[\"emotion\"] = df[\"emotion\"].astype(str).str.lower().str.strip()\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    processed = 0\n",
    "    valid_rows = df\n",
    "    \n",
    "    for idx, row in valid_rows.iterrows():\n",
    "        img_name = row['image']\n",
    "        full_path = os.path.join(image_dir, img_name)\n",
    "        \n",
    "        if os.path.exists(full_path):\n",
    "            try:\n",
    "                img = imread(full_path, as_gray=True)\n",
    "                img = resize(img, img_size, anti_aliasing=True)\n",
    "\n",
    "                features = hog(img, orientations=9, pixels_per_cell=(8, 8), \n",
    "                               cells_per_block=(2, 2), block_norm=\"L2-Hys\")\n",
    "                X.append(features)\n",
    "                y.append(row['emotion'])\n",
    "                processed += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        if processed % 1000 == 0 and processed > 0:\n",
    "            print(f\"Processed {processed} images...\")\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load Data\n",
    "X, y = load_data_hog()\n",
    "\n",
    "if X is None or len(X) == 0:\n",
    "    print(\"CRITICAL ERROR: No data loaded.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Final Data Shape: {X.shape}\")\n",
    "\n",
    "# 80 / 20 Data Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Adaptation Graph\n",
    "depths = [5, 10, 20, 50, 100, None]\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "print(\"Running Depth Adaptation...\")\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, min_samples_split=2, class_weight='balanced', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    train_accs.append(accuracy_score(y_train, clf.predict(X_train)))\n",
    "    test_accs.append(accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_labels = [str(d) if d is not None else \"None\" for d in depths]\n",
    "plt.plot(x_labels, train_accs, label='Training Accuracy', marker='o', linestyle='--')\n",
    "plt.plot(x_labels, test_accs, label='Validation Accuracy', marker='o', linewidth=3)\n",
    "plt.title('Adaptation: Depth vs. Accuracy (Aggressive Splitting)')\n",
    "plt.xlabel('Tree Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(script_dir, 'adaptation_graph.png'))\n",
    "print(\"Graph saved as 'adaptation_graph.png'\")\n",
    "\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [None, 50],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'ccp_alpha': [0.0, 0.001, 0.002]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(class_weight='balanced', random_state=42), \n",
    "                    param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "\n",
    "# Results\n",
    "y_pred = best_model.predict(X_test)\n",
    "final_acc = accuracy_score(y_test, y_pred)\n",
    "final_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"=\"*40)\n",
    "print(f\"Model:      Decision Tree (Optimized)\")\n",
    "print(f\"Accuracy:   {final_acc:.2%}\")\n",
    "print(f\"F1-Score:   {final_f1:.4f}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "plt.title(f'Confusion Matrix (Acc={final_acc:.2%})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(script_dir, 'confusion_matrix.png'))\n",
    "print(\"Confusion Matrix saved as 'confusion_matrix.png'\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
